{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data into dataframe\n",
    "training_data_folder = 'json_gender_data'\n",
    "data = []\n",
    "\n",
    "for folder in sorted(os.listdir(training_data_folder)):\n",
    "    if folder[0] == '.':\n",
    "        continue\n",
    "    sub_folder = os.path.join(training_data_folder,folder)\n",
    "    files = [{'label':folder,'path':os.path.join(sub_folder, f)} for f in os.listdir(sub_folder) if os.path.isfile(os.path.join(sub_folder, f))]\n",
    "    data += files\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "map_characters = {0: 'M', 1: 'W'}\n",
    "\n",
    "order_list = ['M', 'W']\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb = LabelBinarizer()\n",
    "hotEncodedLabels = lb.fit_transform(order_list)\n",
    "hotEncodedLabels\n",
    "\n",
    "#This code will only load the folders for 'M' (man) and 'W' (woman) from the training data folder, and label the data as either \"man\" or \"woman\".\n",
    "#The hot encoded labels will also be changed to [1,0] for \"man\" and [0,1] for \"woman\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'json_gender_data'\n",
    "\n",
    "map_characters = {0: 'M', 1: 'W'}\n",
    "\n",
    "labels_dict = {'M': 0, 'W': 1}\n",
    "\n",
    "order_list = ('M', 'W')\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Loads data and preprocess. Returns train and test data along with labels.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    size = 29,400\n",
    "    num=0\n",
    "\n",
    "    print(\"LOADING DATA FROM : \",end = \"\")\n",
    "    for folder in os.listdir(train_dir): ## to check \n",
    "        if folder[0] == '.':\n",
    "            continue\n",
    "        print(folder, end = ' | ')\n",
    "        for json_file in os.listdir(train_dir + \"/\" + folder):\n",
    "            # temp_img = cv2.imread(train_dir + '/' + folder + '/' + json_file)\n",
    "            # temp_img = cv2.resize(temp_img, size)\n",
    "            temp_json_file = json.load(open(train_dir + '/' + folder + '/' + json_file))\n",
    "            #temp_json_file = temp_json_file[0]\n",
    "            #print(\"CURRENT SHAPE\", np.array(temp_json_file).shape)\n",
    "            temp_np_array = np.array(temp_json_file)\n",
    "            temp = [cv2.resize(temp_np_array[0], size)]\n",
    "            temp_img = np.array(temp)\n",
    "            #print(\"CURRENT SHAPE222\", temp_img.shape)\n",
    "            # temp_np_array = np.array(temp_json_file)\n",
    "            # temp_json_file = np.array(temp_json_file)\n",
    "            # load the list from the json file into a numpy array\n",
    "            # temp_tensor_array = tf.convert_to_tensor(temp_json_file)\n",
    "            # plt.imshow(cv2.cvtColor(temp_img, cv2.COLOR_BGR2RGB))\n",
    "            # plt.show()\n",
    "            # temp_img = temp_img.flatten()\n",
    "            images.append(temp_img)\n",
    "            labels.append(num)\n",
    "        num+=1\n",
    "    \n",
    "    # print(\"\\nHERE\",  images[0])\n",
    "    #print(\"\\nHERE  SHAPE\", images[0].shape)\n",
    "    images = np.array(images)\n",
    "    # images = images.astype('float32')/255\n",
    "    \n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(images, labels, test_size = 0.3, random_state=42)\n",
    "    X_test, X_validation, Y_test, Y_validation = train_test_split(X_test, Y_test, test_size = 0.8,random_state=42)\n",
    "    \n",
    "    \n",
    "    print()\n",
    "    print('Loaded', len(X_train),'images for training,','Train data shape =',X_train.shape)\n",
    "    print('Loaded', len(X_validation),'images for validation','validation data shape =',X_validation.shape)\n",
    "    print('Loaded', len(X_test),'images for testing','Test data shape =',X_test.shape)\n",
    "    print('\\n')\n",
    "\n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test, X_validation, Y_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING DATA FROM : M | W | \n",
      "Loaded 693 images for training, Train data shape = (693, 1, 400, 29)\n",
      "Loaded 238 images for validation validation data shape = (238, 1, 400, 29)\n",
      "Loaded 59 images for testing Test data shape = (59, 1, 400, 29)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test, X_validation, Y_validation= load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_18 (Conv2D)          (None, 1, 200, 96)        136512    \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 1, 200, 96)       384       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 1, 100, 96)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 1, 50, 256)        614656    \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 1, 50, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 1, 25, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 1, 25, 384)        885120    \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 1, 25, 384)       1536      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 1, 25, 256)        884992    \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 1, 25, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 1, 25, 256)        590080    \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 1, 25, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 1, 13, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 1, 13, 4096)       9441280   \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 1, 13, 4096)       0         \n",
      "                                                                 \n",
      " global_average_pooling2d_3   (None, 4096)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1024)              4195328   \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2)                 2050      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,755,010\n",
      "Trainable params: 16,752,514\n",
      "Non-trainable params: 2,496\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# with tf.device('/CPU:0'):\n",
    "#     model = keras.models.Sequential()\n",
    "   \n",
    "#     model.add(layers.Conv2D(8, (5,5), strides=(1,1), padding=\"valid\", activation='relu', input_shape=(64,448,3)))\n",
    "#     model.add(layers.MaxPool2D((2,2)))\n",
    "#     model.add(layers.Conv2D(16, 5, activation='relu'))\n",
    "#     model.add(layers.MaxPool2D((2,2)))\n",
    "#     model.add(layers.Conv2D(32,5, activation='relu'))\n",
    "#     model.add(layers.MaxPool2D((2,2)))\n",
    "#     model.add(layers.Flatten())\n",
    "#     model.add(layers.Dense(100, activation='relu'))\n",
    "#     model.add(layers.Dense(2))\n",
    "#     print(model.summary())\n",
    "DROP_OUT = 0.5\n",
    "NUM_OF_SPEAKERS = 2\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    model = keras.models.Sequential()\n",
    "   \n",
    "    model.add(layers.Conv2D(96, (7,7), strides=(2,2), padding=\"same\", activation='relu', input_shape=(1,400,29)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPool2D((3,3), strides=(2,2), padding=\"same\"))\n",
    "\n",
    "    model.add(layers.Conv2D(256, (5,5), strides=(2,2), padding=\"same\", activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPool2D((3,3), strides=(2,2), padding=\"same\"))\n",
    "\n",
    "    model.add(layers.Conv2D(384, (3,3), strides=(1,1), padding=\"same\", activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Conv2D(256, (3,3), strides=(1,1), padding=\"same\", activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Conv2D(256, (3,3), strides=(1,1), padding=\"same\", activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPool2D((5,3), strides=(3,2), padding=\"same\"))\n",
    "\n",
    "    model.add(layers.Conv2D(4096, (9,1), strides=(1,1), padding=\"same\", activation='relu'))\n",
    "    model.add(layers.Dropout(rate=DROP_OUT))\n",
    "\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "    model.add(layers.Dense(1024, activation='relu'))\n",
    "    model.add(layers.Dropout(rate=DROP_OUT))\n",
    "\n",
    "    model.add(layers.Dense(NUM_OF_SPEAKERS))\n",
    "    \n",
    "    print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    # loss and optimizer\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    optim = keras.optimizers.Adam(lr=0.001)\n",
    "    metrics = [\"accuracy\"]\n",
    "    model.compile(optimizer=optim, loss=loss, metrics=metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "70/70 - 42s - loss: 0.7093 - accuracy: 0.7056 - 42s/epoch - 606ms/step\n",
      "Epoch 2/15\n",
      "70/70 - 39s - loss: 0.5454 - accuracy: 0.7518 - 39s/epoch - 555ms/step\n",
      "Epoch 3/15\n",
      "70/70 - 39s - loss: 0.4017 - accuracy: 0.8341 - 39s/epoch - 552ms/step\n",
      "Epoch 4/15\n",
      "70/70 - 38s - loss: 0.3672 - accuracy: 0.8586 - 38s/epoch - 549ms/step\n",
      "Epoch 5/15\n",
      "70/70 - 38s - loss: 0.3444 - accuracy: 0.8470 - 38s/epoch - 548ms/step\n",
      "Epoch 6/15\n",
      "70/70 - 38s - loss: 0.2547 - accuracy: 0.8975 - 38s/epoch - 544ms/step\n",
      "Epoch 7/15\n",
      "70/70 - 39s - loss: 0.2861 - accuracy: 0.8990 - 39s/epoch - 552ms/step\n",
      "Epoch 8/15\n",
      "70/70 - 39s - loss: 0.3004 - accuracy: 0.8860 - 39s/epoch - 553ms/step\n",
      "Epoch 9/15\n",
      "70/70 - 39s - loss: 0.1951 - accuracy: 0.9235 - 39s/epoch - 551ms/step\n",
      "Epoch 10/15\n",
      "70/70 - 38s - loss: 0.2308 - accuracy: 0.9206 - 38s/epoch - 546ms/step\n",
      "Epoch 11/15\n",
      "70/70 - 38s - loss: 0.1629 - accuracy: 0.9365 - 38s/epoch - 543ms/step\n",
      "Epoch 12/15\n",
      "70/70 - 38s - loss: 0.1577 - accuracy: 0.9452 - 38s/epoch - 547ms/step\n",
      "Epoch 13/15\n",
      "70/70 - 38s - loss: 0.1906 - accuracy: 0.9408 - 38s/epoch - 544ms/step\n",
      "Epoch 14/15\n",
      "70/70 - 38s - loss: 0.1192 - accuracy: 0.9509 - 38s/epoch - 544ms/step\n",
      "Epoch 15/15\n",
      "70/70 - 38s - loss: 0.0955 - accuracy: 0.9697 - 38s/epoch - 543ms/step\n",
      "eval\n",
      "24/24 - 1s - loss: 1.0778 - accuracy: 0.8403 - 1s/epoch - 52ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "70/70 - 38s - loss: 0.2209 - accuracy: 0.9177 - 38s/epoch - 545ms/step\n",
      "Epoch 2/15\n",
      "70/70 - 38s - loss: 0.1828 - accuracy: 0.9452 - 38s/epoch - 546ms/step\n",
      "Epoch 3/15\n",
      "70/70 - 39s - loss: 0.1365 - accuracy: 0.9481 - 39s/epoch - 551ms/step\n",
      "Epoch 4/15\n",
      "70/70 - 39s - loss: 0.0718 - accuracy: 0.9755 - 39s/epoch - 551ms/step\n",
      "Epoch 5/15\n",
      "70/70 - 39s - loss: 0.0952 - accuracy: 0.9654 - 39s/epoch - 555ms/step\n",
      "Epoch 6/15\n",
      "70/70 - 39s - loss: 0.0689 - accuracy: 0.9697 - 39s/epoch - 551ms/step\n",
      "Epoch 7/15\n",
      "70/70 - 38s - loss: 0.0845 - accuracy: 0.9740 - 38s/epoch - 542ms/step\n",
      "Epoch 8/15\n",
      "70/70 - 38s - loss: 0.0630 - accuracy: 0.9798 - 38s/epoch - 543ms/step\n",
      "Epoch 9/15\n",
      "70/70 - 38s - loss: 0.1016 - accuracy: 0.9639 - 38s/epoch - 544ms/step\n",
      "Epoch 10/15\n",
      "70/70 - 38s - loss: 0.0408 - accuracy: 0.9870 - 38s/epoch - 547ms/step\n",
      "Epoch 11/15\n",
      "70/70 - 38s - loss: 0.0561 - accuracy: 0.9798 - 38s/epoch - 542ms/step\n",
      "Epoch 12/15\n",
      "70/70 - 38s - loss: 0.0188 - accuracy: 0.9957 - 38s/epoch - 541ms/step\n",
      "Epoch 13/15\n",
      "70/70 - 38s - loss: 0.0496 - accuracy: 0.9827 - 38s/epoch - 547ms/step\n",
      "Epoch 14/15\n",
      "70/70 - 38s - loss: 0.1272 - accuracy: 0.9740 - 38s/epoch - 543ms/step\n",
      "Epoch 15/15\n",
      "70/70 - 38s - loss: 0.0785 - accuracy: 0.9697 - 38s/epoch - 538ms/step\n",
      "eval\n",
      "24/24 - 1s - loss: 0.3457 - accuracy: 0.8866 - 923ms/epoch - 38ms/step\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    data_x=np.array(X_train)\n",
    "    data_y=np.array(Y_train)\n",
    "\n",
    "    #print(data_x)\n",
    "    #print(data_y)\n",
    "\n",
    "    val_x=np.array(X_validation)\n",
    "    val_y=np.array(Y_validation)\n",
    "\n",
    "    # training\n",
    "    batch_size = 10\n",
    "    epochs = 15\n",
    "    model.fit(data_x, data_y, epochs=epochs, batch_size=batch_size, verbose=2)\n",
    "    print(\"eval\")\n",
    "    model.evaluate(val_x,  val_y, batch_size=batch_size, verbose=2)\n",
    "    \n",
    "    epochs = 15\n",
    "    optim = keras.optimizers.Adam(lr=0.0001)\n",
    "    model.fit(data_x, data_y, epochs=epochs, batch_size=batch_size, verbose=2)\n",
    "    print(\"eval\")\n",
    "    model.evaluate(val_x,  val_y, batch_size=batch_size, verbose=2)\n",
    "\n",
    "    # evaulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to model.h5 file\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "2/2 - 0s - loss: 0.7848 - accuracy: 0.8136 - 197ms/epoch - 98ms/step\n",
      "2/2 [==============================] - 0s 99ms/step\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    test_x=np.array(X_test)\n",
    "    test_y=np.array(Y_test)\n",
    "    \n",
    "    \n",
    "    print(\"test\")\n",
    "    \n",
    "    model.evaluate(test_x,  test_y,verbose=2)\n",
    "    mypred=model.predict(test_x)\n",
    "    mypred=mypred.argmax(axis=1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score,f1_score\n",
    "with tf.device('/CPU:0'):\n",
    "    acc = accuracy_score(Y_test, mypred)\n",
    "    prec = precision_score(Y_test, mypred)\n",
    "    rec = recall_score(Y_test, mypred)\n",
    "    f1 = f1_score(Y_test, mypred)\n",
    "    \n",
    "    # Print the results\n",
    "    print(\"Accuracy: {:.2f}\".format(acc))\n",
    "    print(\"Precision: {:.2f}\".format(prec))\n",
    "    print(\"Recall: {:.2f}\".format(rec))\n",
    "    print(\"F1-Score: {:.2f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# function to make pretty confusion matrix\n",
    "def confussion_matrix(cf_matrix):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    sns.heatmap(cf_matrix, annot=True, fmt='', cmap='Greens')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# create the cunfusion matrix\n",
    "confussion_matrix(confusion_matrix(test_y,mypred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "33c99ce92ae57a37c90157b7c35934b668ba43f0729fdf7df53b30c6721ba8f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
