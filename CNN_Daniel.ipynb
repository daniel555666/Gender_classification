{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data into dataframe\n",
    "training_data_folder = 'json_gender_data'\n",
    "data = []\n",
    "\n",
    "for folder in sorted(os.listdir(training_data_folder)):\n",
    "    if folder[0] == '.':\n",
    "        continue\n",
    "    sub_folder = os.path.join(training_data_folder,folder)\n",
    "    files = [{'label':folder,'path':os.path.join(sub_folder, f)} for f in os.listdir(sub_folder) if os.path.isfile(os.path.join(sub_folder, f))]\n",
    "    data += files\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "map_characters = {0: 'M', 1: 'W'}\n",
    "\n",
    "order_list = ['M', 'W']\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb = LabelBinarizer()\n",
    "hotEncodedLabels = lb.fit_transform(order_list)\n",
    "hotEncodedLabels\n",
    "\n",
    "#This code will only load the folders for 'M' (man) and 'W' (woman) from the training data folder, and label the data as either \"man\" or \"woman\".\n",
    "#The hot encoded labels will also be changed to [1,0] for \"man\" and [0,1] for \"woman\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'json_gender_data'\n",
    "\n",
    "map_characters = {0: 'M', 1: 'W'}\n",
    "\n",
    "labels_dict = {'M': 0, 'W': 1}\n",
    "\n",
    "order_list = ('M', 'W')\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Loads data and preprocess. Returns train and test data along with labels.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    size = 29,400\n",
    "    num=0\n",
    "\n",
    "    print(\"LOADING DATA FROM : \",end = \"\")\n",
    "    for folder in os.listdir(train_dir): ## to check \n",
    "        if folder[0] == '.':\n",
    "            continue\n",
    "        print(folder, end = ' | ')\n",
    "        for json_file in os.listdir(train_dir + \"/\" + folder):\n",
    "            temp_json_file = json.load(open(train_dir + '/' + folder + '/' + json_file))\n",
    "            temp_np_array = np.array(temp_json_file)\n",
    "            temp = [cv2.resize(temp_np_array[0], size)]\n",
    "            temp_img = np.array(temp)\n",
    "            # plt.imshow(cv2.cvtColor(temp_img, cv2.COLOR_BGR2RGB))\n",
    "            # plt.show()\n",
    "            images.append(temp_img)\n",
    "            labels.append(num)\n",
    "        num+=1\n",
    "    \n",
    "    \n",
    "    images = np.array(images)\n",
    "    # images = images.astype('float32')/255\n",
    "    \n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(images, labels, test_size = 0.3, random_state=42)\n",
    "    X_test, X_validation, Y_test, Y_validation = train_test_split(X_test, Y_test, test_size = 0.8,random_state=42)\n",
    "    \n",
    "    \n",
    "    print()\n",
    "    print('Loaded', len(X_train),'images for training,','Train data shape =',X_train.shape)\n",
    "    print('Loaded', len(X_validation),'images for validation','validation data shape =',X_validation.shape)\n",
    "    print('Loaded', len(X_test),'images for testing','Test data shape =',X_test.shape)\n",
    "    print('\\n')\n",
    "\n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test, X_validation, Y_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING DATA FROM : M | W | \n",
      "Loaded 693 images for training, Train data shape = (693, 1, 400, 29)\n",
      "Loaded 238 images for validation validation data shape = (238, 1, 400, 29)\n",
      "Loaded 59 images for testing Test data shape = (59, 1, 400, 29)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test, X_validation, Y_validation= load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_18 (Conv2D)          (None, 1, 200, 96)        136512    \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 1, 200, 96)       384       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 1, 100, 96)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 1, 50, 256)        614656    \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 1, 50, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 1, 25, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 1, 25, 384)        885120    \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 1, 25, 384)       1536      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 1, 25, 256)        884992    \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 1, 25, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 1, 25, 256)        590080    \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 1, 25, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 1, 13, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 1, 13, 4096)       9441280   \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 1, 13, 4096)       0         \n",
      "                                                                 \n",
      " global_average_pooling2d_3   (None, 4096)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1024)              4195328   \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2)                 2050      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,755,010\n",
      "Trainable params: 16,752,514\n",
      "Non-trainable params: 2,496\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DROP_OUT = 0.5\n",
    "NUM_OF_SPEAKERS = 2\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    model = keras.models.Sequential()\n",
    "   \n",
    "    model.add(layers.Conv2D(96, (7,7), strides=(2,2), padding=\"same\", activation='relu', input_shape=(1,400,29)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPool2D((3,3), strides=(2,2), padding=\"same\"))\n",
    "\n",
    "    model.add(layers.Conv2D(256, (5,5), strides=(2,2), padding=\"same\", activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPool2D((3,3), strides=(2,2), padding=\"same\"))\n",
    "\n",
    "    model.add(layers.Conv2D(384, (3,3), strides=(1,1), padding=\"same\", activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Conv2D(256, (3,3), strides=(1,1), padding=\"same\", activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Conv2D(256, (3,3), strides=(1,1), padding=\"same\", activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPool2D((5,3), strides=(3,2), padding=\"same\"))\n",
    "\n",
    "    model.add(layers.Conv2D(4096, (9,1), strides=(1,1), padding=\"same\", activation='relu'))\n",
    "    model.add(layers.Dropout(rate=DROP_OUT))\n",
    "\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "    model.add(layers.Dense(1024, activation='relu'))\n",
    "    model.add(layers.Dropout(rate=DROP_OUT))\n",
    "\n",
    "    model.add(layers.Dense(NUM_OF_SPEAKERS))\n",
    "    \n",
    "    print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    # loss and optimizer\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    optim = keras.optimizers.Adam(lr=0.001)\n",
    "    metrics = [\"accuracy\"]\n",
    "    model.compile(optimizer=optim, loss=loss, metrics=metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "70/70 - 42s - loss: 0.7093 - accuracy: 0.7056 - 42s/epoch - 606ms/step\n",
      "Epoch 2/15\n",
      "70/70 - 39s - loss: 0.5454 - accuracy: 0.7518 - 39s/epoch - 555ms/step\n",
      "Epoch 3/15\n",
      "70/70 - 39s - loss: 0.4017 - accuracy: 0.8341 - 39s/epoch - 552ms/step\n",
      "Epoch 4/15\n",
      "70/70 - 38s - loss: 0.3672 - accuracy: 0.8586 - 38s/epoch - 549ms/step\n",
      "Epoch 5/15\n",
      "70/70 - 38s - loss: 0.3444 - accuracy: 0.8470 - 38s/epoch - 548ms/step\n",
      "Epoch 6/15\n",
      "70/70 - 38s - loss: 0.2547 - accuracy: 0.8975 - 38s/epoch - 544ms/step\n",
      "Epoch 7/15\n",
      "70/70 - 39s - loss: 0.2861 - accuracy: 0.8990 - 39s/epoch - 552ms/step\n",
      "Epoch 8/15\n",
      "70/70 - 39s - loss: 0.3004 - accuracy: 0.8860 - 39s/epoch - 553ms/step\n",
      "Epoch 9/15\n",
      "70/70 - 39s - loss: 0.1951 - accuracy: 0.9235 - 39s/epoch - 551ms/step\n",
      "Epoch 10/15\n",
      "70/70 - 38s - loss: 0.2308 - accuracy: 0.9206 - 38s/epoch - 546ms/step\n",
      "Epoch 11/15\n",
      "70/70 - 38s - loss: 0.1629 - accuracy: 0.9365 - 38s/epoch - 543ms/step\n",
      "Epoch 12/15\n",
      "70/70 - 38s - loss: 0.1577 - accuracy: 0.9452 - 38s/epoch - 547ms/step\n",
      "Epoch 13/15\n",
      "70/70 - 38s - loss: 0.1906 - accuracy: 0.9408 - 38s/epoch - 544ms/step\n",
      "Epoch 14/15\n",
      "70/70 - 38s - loss: 0.1192 - accuracy: 0.9509 - 38s/epoch - 544ms/step\n",
      "Epoch 15/15\n",
      "70/70 - 38s - loss: 0.0955 - accuracy: 0.9697 - 38s/epoch - 543ms/step\n",
      "eval\n",
      "24/24 - 1s - loss: 1.0778 - accuracy: 0.8403 - 1s/epoch - 52ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "70/70 - 38s - loss: 0.2209 - accuracy: 0.9177 - 38s/epoch - 545ms/step\n",
      "Epoch 2/15\n",
      "70/70 - 38s - loss: 0.1828 - accuracy: 0.9452 - 38s/epoch - 546ms/step\n",
      "Epoch 3/15\n",
      "70/70 - 39s - loss: 0.1365 - accuracy: 0.9481 - 39s/epoch - 551ms/step\n",
      "Epoch 4/15\n",
      "70/70 - 39s - loss: 0.0718 - accuracy: 0.9755 - 39s/epoch - 551ms/step\n",
      "Epoch 5/15\n",
      "70/70 - 39s - loss: 0.0952 - accuracy: 0.9654 - 39s/epoch - 555ms/step\n",
      "Epoch 6/15\n",
      "70/70 - 39s - loss: 0.0689 - accuracy: 0.9697 - 39s/epoch - 551ms/step\n",
      "Epoch 7/15\n",
      "70/70 - 38s - loss: 0.0845 - accuracy: 0.9740 - 38s/epoch - 542ms/step\n",
      "Epoch 8/15\n",
      "70/70 - 38s - loss: 0.0630 - accuracy: 0.9798 - 38s/epoch - 543ms/step\n",
      "Epoch 9/15\n",
      "70/70 - 38s - loss: 0.1016 - accuracy: 0.9639 - 38s/epoch - 544ms/step\n",
      "Epoch 10/15\n",
      "70/70 - 38s - loss: 0.0408 - accuracy: 0.9870 - 38s/epoch - 547ms/step\n",
      "Epoch 11/15\n",
      "70/70 - 38s - loss: 0.0561 - accuracy: 0.9798 - 38s/epoch - 542ms/step\n",
      "Epoch 12/15\n",
      "70/70 - 38s - loss: 0.0188 - accuracy: 0.9957 - 38s/epoch - 541ms/step\n",
      "Epoch 13/15\n",
      "70/70 - 38s - loss: 0.0496 - accuracy: 0.9827 - 38s/epoch - 547ms/step\n",
      "Epoch 14/15\n",
      "70/70 - 38s - loss: 0.1272 - accuracy: 0.9740 - 38s/epoch - 543ms/step\n",
      "Epoch 15/15\n",
      "70/70 - 38s - loss: 0.0785 - accuracy: 0.9697 - 38s/epoch - 538ms/step\n",
      "eval\n",
      "24/24 - 1s - loss: 0.3457 - accuracy: 0.8866 - 923ms/epoch - 38ms/step\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    data_x=np.array(X_train)\n",
    "    data_y=np.array(Y_train)\n",
    "\n",
    "    val_x=np.array(X_validation)\n",
    "    val_y=np.array(Y_validation)\n",
    "\n",
    "    # training\n",
    "    batch_size = 10\n",
    "    epochs = 15\n",
    "    model.fit(data_x, data_y, epochs=epochs, batch_size=batch_size, verbose=2)\n",
    "    print(\"eval\")\n",
    "    model.evaluate(val_x,  val_y, batch_size=batch_size, verbose=2)\n",
    "    \n",
    "    epochs = 15\n",
    "    optim = keras.optimizers.Adam(lr=0.0001)\n",
    "    model.fit(data_x, data_y, epochs=epochs, batch_size=batch_size, verbose=2)\n",
    "    print(\"eval\")\n",
    "    model.evaluate(val_x,  val_y, batch_size=batch_size, verbose=2)\n",
    "\n",
    "    # evaulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to model.h5 file\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "2/2 - 0s - loss: 0.7848 - accuracy: 0.8136 - 197ms/epoch - 98ms/step\n",
      "2/2 [==============================] - 0s 99ms/step\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    test_x=np.array(X_test)\n",
    "    test_y=np.array(Y_test)\n",
    "    \n",
    "    \n",
    "    print(\"test\")\n",
    "    \n",
    "    model.evaluate(test_x,  test_y,verbose=2)\n",
    "    mypred=model.predict(test_x)\n",
    "    mypred=mypred.argmax(axis=1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81\n",
      "Precision: 0.88\n",
      "Recall: 0.80\n",
      "F1-Score: 0.84\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score,f1_score\n",
    "with tf.device('/CPU:0'):\n",
    "    acc = accuracy_score(Y_test, mypred)\n",
    "    prec = precision_score(Y_test, mypred)\n",
    "    rec = recall_score(Y_test, mypred)\n",
    "    f1 = f1_score(Y_test, mypred)\n",
    "    \n",
    "    # Print the results\n",
    "    print(\"Accuracy: {:.2f}\".format(acc))\n",
    "    print(\"Precision: {:.2f}\".format(prec))\n",
    "    print(\"Recall: {:.2f}\".format(rec))\n",
    "    print(\"F1-Score: {:.2f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# function to make pretty confusion matrix\n",
    "def confussion_matrix(cf_matrix):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    sns.heatmap(cf_matrix, annot=True, fmt='', cmap='Greens')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# create the cunfusion matrix\n",
    "confussion_matrix(confusion_matrix(test_y,mypred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "33c99ce92ae57a37c90157b7c35934b668ba43f0729fdf7df53b30c6721ba8f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
